{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d5PPXboLNW",
        "outputId": "97d0126b-e491-4383-a016-3cc323da062e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2025.6.15)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install tweepy nltk pandas python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = (\"API_KEY\")\n",
        "api_secret = (\"API_SECRET\")\n",
        "access_token = (\"ACCESS_TOKEN\")\n",
        "access_token_secret = (\"ACCESS_TOKEN_SECRET\")\n",
        "bearer_token = (\"BEARER_TOKEN\")"
      ],
      "metadata": {
        "id": "ebdx_ozgpY_y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "client = tweepy.Client(bearer_token=bearer_token)\n",
        "\n",
        "def fetch_tweets(query=\"Nike\", max_results=50):\n",
        "    response = client.search_recent_tweets(\n",
        "        query=query,\n",
        "        max_results=max_results,\n",
        "        tweet_fields=[\"text\", \"lang\"]\n",
        "    )\n",
        "\n",
        "    tweets = []\n",
        "    if response.data:\n",
        "        for tweet in response.data:\n",
        "            if tweet.lang == \"en\":\n",
        "                tweets.append(tweet.text)\n",
        "\n",
        "    return tweets"
      ],
      "metadata": {
        "id": "ZaLNiLrdrF38"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkvLnUSwrxxr",
        "outputId": "3a258a9b-100d-4fe7-ffa0-c58792843c0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "def log_sentiment(tweet_text):\n",
        "\n",
        "    sentiment = get_sentiment(tweet_text)\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    import os\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs('data')\n",
        "\n",
        "    with open('data/sentiment_logs.csv', 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([now, tweet_text,sentiment])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1WnmfqwctHuI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [\n",
        "    (\"I love this new phone!\", \"Positive\"),\n",
        "    (\"This is the worst experience ever.\", \"Negative\"),\n",
        "    (\"Itâ€™s okay, nothing special.\", \"Neutral\"),\n",
        "    (\"Amazing product! Highly recommend it.\", \"Positive\"),\n",
        "    (\"Terrible service from the brand.\",\"Negative\")\n",
        "]"
      ],
      "metadata": {
        "id": "b7t-PrRWt8M4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def clean_text(text):\n",
        "    import re\n",
        "    text = re.sub(r\"http\\S+|@\\S+|#\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "def get_sentiment(text):\n",
        "    cleaned = clean_text(text)\n",
        "    score = sia.polarity_scores(cleaned)['compound']\n",
        "    if score >= 0.05:\n",
        "        return \"Positive\"\n",
        "    elif score <= -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xYTCScaLLlW",
        "outputId": "d21e1cfa-d76c-4c1e-dfcd-409cc3fd888a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for tweet, label in test_data:\n",
        "    y_true.append(label)\n",
        "    y_pred.append(get_sentiment(tweet))\n",
        "\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bch_RrAnLUq6",
        "outputId": "9b7b56c6-54df-4b6d-ce17-dcde5101bc17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.67      1.00      0.80         2\n",
            "     Neutral       0.00      0.00      0.00         1\n",
            "    Positive       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.56      0.67      0.60         5\n",
            "weighted avg       0.67      0.80      0.72         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Ba2pdi8Le16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}